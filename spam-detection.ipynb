{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d00d20e",
   "metadata": {},
   "source": [
    "# **Spam Email Detection — Naive Bayes (Machine Learning)**\n",
    "\n",
    "This notebook contains a simple, reproducible implementation of an email spam detection pipeline using the Naive Bayes classifier. The project uses the \"Spam Email Classification\" dataset from Kaggle and demonstrates data loading, preprocessing, model training, evaluation, and basic model export."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e1fba",
   "metadata": {},
   "source": [
    "## **Step 00** : Install nessessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4541d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.10/site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy pandas nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72b997",
   "metadata": {},
   "source": [
    "## **Step 01** : Data loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a50ef320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  5572 non-null   object\n",
      " 1   Message   5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ezzoubair/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Load Data from CSV file\n",
    "df = pd.read_csv(\"data/email.csv\")\n",
    "\n",
    "# Get Some info about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef38a5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "     Category                                            Message\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n"
     ]
    }
   ],
   "source": [
    "# print the first and last 5 values to ch\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8917b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                            Message\n",
      "0        0  Go until jurong point, crazy.. Available only ...\n",
      "1        0                      Ok lar... Joking wif u oni...\n",
      "2        1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3        0  U dun say so early hor... U c already then say...\n",
      "4        0  Nah I don't think he goes to usf, he lives aro...\n",
      "     Category                                            Message\n",
      "5567        1  This is the 2nd time we have tried 2 contact u...\n",
      "5568        0               Will ü b going to esplanade fr home?\n",
      "5569        0  Pity, * was in mood for that. So...any other s...\n",
      "5570        0  The guy did some bitching but I acted like i'd...\n",
      "5571        0                         Rofl. Its true to its name\n"
     ]
    }
   ],
   "source": [
    "# Change the category to a binary values (0 or 1) based on the message is spam (1) or not spam (0)\n",
    "df.loc[df[\"Category\"] == \"ham\",\"Category\"] = 0\n",
    "df.loc[df[\"Category\"] == \"spam\",\"Category\"] = 1\n",
    "\n",
    "\n",
    "# print the first and last 5 values to ch\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce14578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and processing Function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # Remove punctuation using regEx\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    words = text.split()\n",
    "    # Remove stopwords and short words (optional: words <= 2 chars)\n",
    "    words = [w for w in words if w not in stop_words and len(w) > 3]\n",
    "    return words\n",
    "\n",
    "df[\"Message\"] = df[\"Message\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6220b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[jurong, point, crazy, available, bugis, great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[joking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, wkly, comp, final, tkts, 21st, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[early, already]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[dont, think, goes, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0        0  [jurong, point, crazy, available, bugis, great...\n",
       "1        0                                           [joking]\n",
       "2        1  [free, entry, wkly, comp, final, tkts, 21st, 2...\n",
       "3        0                                   [early, already]\n",
       "4        0         [dont, think, goes, lives, around, though]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect Data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39255efd",
   "metadata": {},
   "source": [
    "**And that it for the data manipulation we need for now !!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acfd0a",
   "metadata": {},
   "source": [
    "## **Step 02** : Feature Extraction for Text\n",
    "in other words, we need to extract meaning from the data we made !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d01ab6",
   "metadata": {},
   "source": [
    "### Create vocabolary from messages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f508b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38061\n",
      "8295\n"
     ]
    }
   ],
   "source": [
    "# merge all tokens into one  big list\n",
    "messages_tokens = sum(df[\"Message\"],[])\n",
    "print(len(messages_tokens))\n",
    "\n",
    "# Eleminate duplicate\n",
    "vocabulary = list(set(messages_tokens))\n",
    "\n",
    "vocab_array = np.array(vocabulary)\n",
    "\n",
    "print(len(vocab_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db2480a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>[time, tried, contact, pound, prize, claim, ea...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>[going, esplanade, home]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>[pity, mood, soany, suggestions]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>[bitching, acted, like, interested, buying, so...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  \\\n",
       "5567        1  [time, tried, contact, pound, prize, claim, ea...   \n",
       "5568        0                           [going, esplanade, home]   \n",
       "5569        0                   [pity, mood, soany, suggestions]   \n",
       "5570        0  [bitching, acted, like, interested, buying, so...   \n",
       "5571        0                                 [rofl, true, name]   \n",
       "\n",
       "                                                 vector  \n",
       "5567  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5568  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5569  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5570  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5571  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx = {word: i for i, word in enumerate(vocab_array)}\n",
    "\n",
    "def vectorize_message(message):\n",
    "    vec = np.zeros(len(vocab_array), dtype=int)\n",
    "    for w in message:\n",
    "        if w in word_to_idx:\n",
    "            vec[word_to_idx[w]] += 1\n",
    "    return vec\n",
    "\n",
    "\n",
    "\n",
    "df[\"vector\"] = df[\"Message\"].apply(vectorize_message)\n",
    "\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e570791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_category = np.array(df[\"Category\"])\n",
    "train_matrix = np.array(df[\"vector\"])\n",
    "\n",
    "def trainNB0(train_matrix,train_category):\n",
    "    numTrainDocs = len(train_matrix)\n",
    "    numWords = len(train_matrix[0])\n",
    "    pSpam = sum(train_category) / float(numTrainDocs)\n",
    "    p0Num = np.zeros(numWords)\n",
    "    p1Num = np.zeros(numWords)\n",
    "    p0Denom = 0.0\n",
    "    p1Denom = 0.0\n",
    "\n",
    "    for i in range(numTrainDocs):\n",
    "        if train_category[i] == 1:\n",
    "            p1Num += train_matrix[i]\n",
    "            p1Denom += sum(train_matrix[i])\n",
    "        else:\n",
    "            p0Num += train_matrix[i]\n",
    "            p0Denom += sum(train_matrix[i])\n",
    "\n",
    "    p1Vect = (1 + p1Num) / (2 + p1Denom)\n",
    "    p0Vect = (1 + p0Num) / (2 + p0Denom)\n",
    "    return p0Vect, p1Vect, pSpam\n",
    "\n",
    "p0V, p1V, pSpam = trainNB0(train_matrix, train_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770f75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello Valued Customer,\n",
      "\n",
      "CONGRATULATIONS!!! You have been randomly SELECTED to receive an exclusive $2,000 shopping voucher to celebrate our anniversary. This is a limited time offer and will expire within 24 hours.\n",
      "\n",
      "To claim your reward, simply confirm your account by clicking the link below and verifying your information. Failure to claim now will result in the voucher being awarded to another winner.\n",
      "\n",
      "[CLAIM YOUR PRIZE — LINK REMOVED FOR SAFETY]\n",
      "\n",
      "Benefits you get immediately:\n",
      "• $2,000 voucher usable at hundreds of top stores\n",
      "• Free expedited shipping for one year\n",
      "• VIP support and bonus coupons\n",
      "\n",
      "This is a one-time offer sent to a small number of customers. Don't miss out — act now!\n",
      "\n",
      "Warm regards,\n",
      "Rewards Team\n",
      "Freetreats Rewards Dept.\n",
      "Contact: support@freetreats-notice.com\n",
      " → 1\n"
     ]
    }
   ],
   "source": [
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    p1 = sum(vec2Classify * np.log(p1Vec)) + np.log(pClass1)\n",
    "    p0 = sum(vec2Classify * np.log(p0Vec)) + np.log(1.0 - pClass1)\n",
    "    return 1 if p1 > p0 else 0\n",
    "\n",
    "\n",
    "\n",
    "test_email = \"\"\"\n",
    "Hello Valued Customer,\n",
    "\n",
    "CONGRATULATIONS!!! You have been randomly SELECTED to receive an exclusive $2,000 shopping voucher to celebrate our anniversary. This is a limited time offer and will expire within 24 hours.\n",
    "\n",
    "To claim your reward, simply confirm your account by clicking the link below and verifying your information. Failure to claim now will result in the voucher being awarded to another winner.\n",
    "\n",
    "[CLAIM YOUR PRIZE — LINK REMOVED FOR SAFETY]\n",
    "\n",
    "Benefits you get immediately:\n",
    "• $2,000 voucher usable at hundreds of top stores\n",
    "• Free expedited shipping for one year\n",
    "• VIP support and bonus coupons\n",
    "\n",
    "This is a one-time offer sent to a small number of customers. Don't miss out — act now!\n",
    "\n",
    "Warm regards,\n",
    "Rewards Team\n",
    "Freetreats Rewards Dept.\n",
    "Contact: support@freetreats-notice.com\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "test_vector =vectorize_message(clean_text(test_email))\n",
    "\n",
    "\n",
    "print(test_email, \"→\", classifyNB(test_vector, p0V, p1V, pSpam))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012b83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
